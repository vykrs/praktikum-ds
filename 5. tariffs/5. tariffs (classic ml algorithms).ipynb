{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выбор тарифа\n",
    "## Описание проекта\n",
    "\n",
    "Оператор мобильной связи «Мегалайн» выяснил: многие клиенты пользуются архивными тарифами. Они хотят построить систему, способную проанализировать поведение клиентов и предложить пользователям новый тариф: «Смарт» или «Ультра».\n",
    "\n",
    "В нашем распоряжении данные о поведении клиентов, которые уже перешли на эти тарифы. Нужно построить модель для задачи классификации, которая выберет подходящий тариф.\n",
    "\n",
    "Требуется построить модель с максимально большим значением _accuracy_ (минимум - 0.75). _Accuracy_ необходимо рассчитать на тестовой выборке самостоятельно.\n",
    "\n",
    "## План выполнения задания\n",
    "\n",
    "1. Открыть и изучить полученный датасет;\n",
    "2. Выделить обучающую, валидационную и тестовую выборки;\n",
    "3. Испытать различные модели для классификации, подбирая оптимальные гиперпараметры; выбрать модель, показывающую наибольшее значение *accuracy*;\n",
    "4. Проверить качество модели на тестовой выборке;\n",
    "5. Дополнительное задание: проверить модели на вменяемость.\n",
    "\n",
    "## Описание данных\n",
    "\n",
    "Файл ___users_behavior.csv___.    \n",
    "Каждый объект в наборе данных — это информация о поведении одного пользователя за месяц. Ивестные параметры:\n",
    "- __сalls__ — количество звонков;\n",
    "- __minutes__ — суммарная длительность звонков в минутах;\n",
    "- __messages__ — количество sms-сообщений;\n",
    "- __mb_used__ — израсходованный интернет-трафик в Мб;\n",
    "- __is_ultra__ — каким тарифом пользовался в течение месяца («Ультра» — 1, «Смарт» — 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые для работы модули:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.model_selection import train_test_split               # разбиение датасета на выборки\n",
    "from sklearn.metrics import accuracy_score                         # показатель точности\n",
    "from sklearn.preprocessing import scale                            # стандартизация\n",
    "\n",
    "from sklearn.dummy import DummyClassifier                          # модели\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "R = 10000                                                          # используемое значение random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Откроем полученный датасет и выведем для наглядности несколько записей, а также информацию о таблице:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "users_behavior = pd.read_csv('/datasets/users_behavior.csv')\n",
    "display(users_behavior.head())\n",
    "users_behavior.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблица содержит 3214 записей, разбитых на 5 столбцов. Предобработка не требуется.\n",
    "\n",
    "Целевым параметром для нашей модели будет столбец __is_ultra__, в котором отражено, какой тариф используется пользователем. Возможные значения данного столбца - *0* (подключен тариф Smart) и *1* (подключен тариф Ultra), соответственно, перед нами стоит задача бинарной классификации. \n",
    "\n",
    "Выделим целевой признак в отдельную переменную ***target***, а остальные признаки сохраним в переменной ***features***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = users_behavior.drop(columns = 'is_ultra')\n",
    "target   = users_behavior['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для корректной работы некоторых алгоритмов обучения требуется, чтобы признаки были нормированы. Произведем их стандартизацию с помощью функции scale из модуля sklearn.preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = scale(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем получившийся датасет на обучающую, валидационную и тестовую выборки в соотношении 3:1:1. Для этого воспользуемся функцией train_test_split из модуля sklearn.model_selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры выборок:\n",
      "\n",
      "Обучающая \t 1928\n",
      "Валидационная \t 643\n",
      "Тестовая \t 643\n"
     ]
    }
   ],
   "source": [
    "tr_and_val_feats, test_feats, tr_and_val_target, test_target = train_test_split(features, \n",
    "                                                                                target,\n",
    "                                                                                train_size = 0.8,   # 4:1\n",
    "                                                                                random_state = R)\n",
    "\n",
    "train_feats, valid_feats, train_target, valid_target = train_test_split(tr_and_val_feats, \n",
    "                                                                        tr_and_val_target,\n",
    "                                                                        train_size = 0.75,          # 3:1\n",
    "                                                                        random_state = R)\n",
    "\n",
    "print(f'''Размеры выборок:\n",
    "\n",
    "Обучающая \\t {train_feats.shape[0]}\n",
    "Валидационная \\t {valid_feats.shape[0]}\n",
    "Тестовая \\t {test_feats.shape[0]}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2. Испытание различных моделей обучения\n",
    "\n",
    "### 1. Критерий оценки\n",
    "\n",
    "Прежде, чем перейти к рассмотрению различных моделей, нам следует определить критерий вменяемости модели. С помощью классификатора DummyClassifier из состава sklearn.dummy проверим, какой точностью будут обладать некоторые примитивные модели классификации. \n",
    "\n",
    "Создадим две модели: первая всегда будет выдавать *0* (наиболее часто встречающийся целевой признак), а вторая - предсказывать результат случайным образом в соответствии с весами классов в датасете - и найдем для них значение метрики **accuracy**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика accuracy для модели 1 (наиболее частое значение):\t\t 0.6935\n",
      "Метрика accuracy для модели 2 (пропорциональный случайный выбор):\t 0.5727\n"
     ]
    }
   ],
   "source": [
    "model_0   = DummyClassifier(strategy = 'most_frequent')\n",
    "model_str = DummyClassifier(strategy = 'stratified')\n",
    "\n",
    "model_0.fit(features, target)\n",
    "print(f'Метрика accuracy для модели 1 (наиболее частое значение):\\t\\t {model_0.score(features, target):.4f}')\n",
    "\n",
    "# Для \"случайной\" модели подсчитаем среднюю точность по итогам нескольких испытаний\n",
    "accuracies = []\n",
    "for _ in range(30):\n",
    "    model_str.fit(features, target)\n",
    "    accuracies.append(model_str.score(features, target))\n",
    "print(f'Метрика accuracy для модели 2 (пропорциональный случайный выбор):\\t {(sum(accuracies)/30):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, в дальнейшем нам нужно исходить из того, что точность предсказаний нашей модели должна быть не менее *0.69*.\n",
    "\n",
    "### 2. Исследование моделей\n",
    "\n",
    "Для решения нашей задачи рассмотрим следующие алгоритмы классификации:\n",
    "1. Логистическая регрессия;\n",
    "2. Наивный байесовский алгоритм;\n",
    "3. К ближайших соседей;\n",
    "4. Метод опорных векторов;\n",
    "5. Решающее дерево;\n",
    "6. Случайный лес.\n",
    "\n",
    "Каждую модель мы будем обучать на тренировочном наборе, а затем определять точность (accuracy) ее предсказаний на валидационных данных.\n",
    "Полученные значения точности будем сохранять в переменную **results**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика accuracy для модели \"Логистическая регрессия\": 0.7683\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(solver = 'liblinear')\n",
    "logreg_model.fit(train_feats, train_target)\n",
    "prediction = logreg_model.predict(valid_feats)\n",
    "results['Логистическая регрессия'] = accuracy_score(valid_target, prediction)\n",
    "\n",
    "print('Метрика accuracy для модели \"Логистическая регрессия\": {:.4f}'\n",
    "      .format(results['Логистическая регрессия']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Наивный алгоритм Байеса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика accuracy для модели \"Наивный байесовский алгоритм\": 0.7963\n"
     ]
    }
   ],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model.fit(train_feats, train_target)\n",
    "prediction = nb_model.predict(valid_feats)\n",
    "results['Наивный байесовский алгоритм'] = accuracy_score(valid_target, prediction)\n",
    "\n",
    "print('Метрика accuracy для модели \"Наивный байесовский алгоритм\": {:.4f}'\n",
    "      .format(results['Наивный байесовский алгоритм']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### К-ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика accuracy для модели \"К ближайших соседей\": 0.8009\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(train_feats, train_target)\n",
    "prediction = knn_model.predict(valid_feats)\n",
    "results['К соседей'] = accuracy_score(valid_target, prediction)\n",
    "print('Метрика accuracy для модели \"К ближайших соседей\": {:.4f}'\n",
    "      .format(results['К соседей']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Метод опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика accuracy для модели \"Метод опорных векторов\": 0.8134\n"
     ]
    }
   ],
   "source": [
    "SVM_model = SVC(gamma = 'auto', random_state = R)\n",
    "SVM_model.fit(train_feats, train_target)\n",
    "prediction = SVM_model.predict(valid_feats)\n",
    "results['Опорные векторы'] = accuracy_score(valid_target, prediction)\n",
    "print('Метрика accuracy для модели \"Метод опорных векторов\": {:.4f}'\n",
    "      .format(results['Опорные векторы']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика accuracy для модели \"Решающее дерево\": 0.7341\n"
     ]
    }
   ],
   "source": [
    "tree_model = DecisionTreeClassifier(random_state = R)\n",
    "tree_model.fit(train_feats, train_target)\n",
    "prediction = tree_model.predict(valid_feats)\n",
    "results['Решающее дерево'] = accuracy_score(valid_target, prediction)\n",
    "print('Метрика accuracy для модели \"Решающее дерево\": {:.4f}'\n",
    "      .format(results['Решающее дерево']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика accuracy для модели \"Случайный лес\": 0.7792\n"
     ]
    }
   ],
   "source": [
    "forest_model = RandomForestClassifier(n_estimators = 10, random_state = R)\n",
    "forest_model.fit(train_feats, train_target)\n",
    "prediction = forest_model.predict(valid_feats)\n",
    "results['Случайный лес'] = accuracy_score(valid_target, prediction)\n",
    "print('Метрика accuracy для модели \"Случайный лес\": {:.4f}'\n",
    "      .format(results['Случайный лес']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Подбор гиперпараметров\n",
    "\n",
    "В итоге нами получены следующие метрики для различных моделей (с параметрами по умолчанию):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Опорные векторы</td>\n",
       "      <td>0.813375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>К соседей</td>\n",
       "      <td>0.800933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Наивный байесовский алгоритм</td>\n",
       "      <td>0.796267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Случайный лес</td>\n",
       "      <td>0.779160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Логистическая регрессия</td>\n",
       "      <td>0.768274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Решающее дерево</td>\n",
       "      <td>0.734059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              accuracy\n",
       "Опорные векторы               0.813375\n",
       "К соседей                     0.800933\n",
       "Наивный байесовский алгоритм  0.796267\n",
       "Случайный лес                 0.779160\n",
       "Логистическая регрессия       0.768274\n",
       "Решающее дерево               0.734059"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_table = pd.DataFrame(data = results.values(), index = results.keys(), columns = ['accuracy'])\n",
    "results_table.sort_values(by = 'accuracy', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем улучшить работу модели \"Случайный лес\". Сперва подберем оптимальные значения количества деревьев (*n_estimators*) и максимальной глубины (*max_depth*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальное значение accuracy равно 0.8196, параметры: n_estimators = 50, max_depth = 9\n"
     ]
    }
   ],
   "source": [
    "grid = []\n",
    "for depth in range (5, 10):\n",
    "    for estimators in range (20, 101, 10):\n",
    "        forest_model = RandomForestClassifier(n_estimators = estimators, max_depth = depth, random_state = R)\n",
    "        forest_model.fit(train_feats, train_target)\n",
    "        prediction = forest_model.predict(valid_feats)\n",
    "        grid.append([accuracy_score(valid_target, prediction), estimators, depth])\n",
    "                       \n",
    "best = max(grid)\n",
    "print(f'Максимальное значение accuracy равно {best[0]:.4f},', \n",
    "     f'параметры: n_estimators = {best[1]}, max_depth = {best[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно видеть, подбор оптимальных гиперпараметров увеличил точность нашей модели с *0.78* до *0.82*, в результате чего она обогнала по данной метрике все остальные рассмотренные классификаторы. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Шаг 3. Проверка модели на тестовом наборе\n",
    "\n",
    "Проверим, как наша модель \"Случайный лес\", показавшая себя лучше всего на валидационных данных, будет работать на тестовом наборе. Для этого сначала обучим ее с использованием валидационного и тренировочного набора, после чего найдем accuracy для тестовых данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоговое значение accuracy - 0.8025\n"
     ]
    }
   ],
   "source": [
    "forest_model.fit(tr_and_val_feats, tr_and_val_target)\n",
    "prediction = forest_model.predict(test_feats)\n",
    "final_score = accuracy_score(test_target, prediction)\n",
    "print(f'Итоговое значение accuracy - {final_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, в итоге мы получили значение accuracy чуть меньше, чем на валидационной выборке, но при этом выше нашей примитивной модели (*0.69*), а также требований задания (*0.75*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "В данной работе перед нами стояла задача построить модель, которая будет выбирать подходящий тариф для клиентов оператора мобильной связи. В нашем распоряжении была информация о поведении пользователей, которые уже перешли на один из двух тарифов.\n",
    "Для решения этой задачи мы сделали следующее:\n",
    "1. Выделили целевой признак (тариф - Ultra или Smart) и сохранили его в отдельную переменную;\n",
    "2. Нормализовали признаки для корректной работы требующих этого алгоритмов (SVM, К ближайших соседей и прочих);\n",
    "3. Разбили наш датасет на три части: тренировочную, валидационную и тестовую;\n",
    "4. Выбрали метрику, по которой будем оценивать качество модели (accuracy) и определили ее минимально разумное значение (оно равно 0.69 и получается, если классификатор независимо от всех признаков будет возвращать *0*);\n",
    "5. Рассмотрели несколько различных алгоритмов классификации и выбрали из них модель \"Случайный лес\" (Random Forest Classifier). После подбора оптимальных гиперпараметров (n_estimators = 50, max_depth = 9, остальные - по умолчанию) наша модель показала точность на валидационном наборе 0.82;\n",
    "\n",
    "Качество получившейся модели мы проверили на тестовом наборе, в результате чего итоговое значение accuracy оказалось равным 0.80, что немного ниже, чем на валидационных данных (произошло незначительное переобучение), однако удовлетворяет условиям задания (точность должна быть не менее 0.75)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

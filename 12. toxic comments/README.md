# Определение токсичности комментариев

### Задание
Необходимо построить модель для поиска токсичных текстовых комментариев. Требуемое значение метрики качества *F1*  - не меньше 0.75. 


## Описание данных

Данные находятся в файле ***toxic_comments.csv***. Столбец **text** в нём содержит текст комментария, а **toxic** — целевой признак.

## Использованные библиотеки

- python + numpy, scipy, pandas (стек для анализа данных)
- matplotlib, seaborn (визуализация)
- NLTK, spaCy (NLP)
- scikit-learn, Light-GBM (машинное обучение)
- profanityfilter (поиск обсценных и ругательных слов)
- pyspellchecker (проверка орфографии)

## Основные шаги и итоги
1. Исследовательский анализ данных - изучены тексты комментариев и баланс классов, рассчитаны численные признаки (количество слов, предложений, абзацев, доля ругательств, доля слов, выделенных капсом и другие) и найдена их корреляция с целевым признаком;
2. Предобработка данных - проведена очистка текстов от ненужных символов, ссылок, стоп-слов, токенизация и лемматизация;
3. Создание признаков - тексты комментариев векторизованы с использованием TF-IDF для отдельных слов и символьных n-грамм;
4. Построение и обучение моделей - исследованы модели логистической регрессии и градиентного бустинга.

Наилучший результат показала модель градиентного бустинга. Значение целевой метрики (F1) на тестовой выборке - **0.81**, что соответствует требованиям задания (F1 больше 0.75)
